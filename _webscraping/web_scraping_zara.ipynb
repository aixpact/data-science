{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping Zara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping rules\n",
    "- You should check a site's terms and conditions before you scrape them. It's their data and they likely have some rules to govern it.\n",
    "- Be nice - A computer will send web requests much quicker than a user can. Make sure you space out your requests a bit so that you don't hammer the site's server.\n",
    "- Scrapers break - Sites change their layout all the time. If that happens, be prepared to rewrite your code.\n",
    "- Web pages are inconsistent - There's sometimes some manual clean up that has to happen even after you've gotten your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import necessary modules</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By \n",
    "# from selenium.webdriver.support.ui import WebDriverWait \n",
    "# from selenium.webdriver.support import expected_conditions as EC \n",
    "# from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium headless driver options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()  \n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "chrome_options.binary_location = '/Applications/Google Chrome Canary.app/Contents/MacOS/Google Chrome Canary'\n",
    "driver_dir = '../_driver_headless/chromedriver'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium browser (not headless) options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser_options = Options()  \n",
    "browser_options.add_argument(\"--incognito\")\n",
    "browser_options.binary_location = '/Applications/Google Chrome Canary.app/Contents/MacOS/Google Chrome Canary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape with browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menu_man = driver.find_element_by_partial_link_text('MAN').click()\n",
    "url ='https://www.zara.com/uk/en/search?searchTerm='\n",
    "keyword = 'man trousers'\n",
    "url += keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(executable_path=os.path.abspath(driver_dir), chrome_options=browser_options)  \n",
    "browser.get(url)\n",
    "browser.current_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scroll until last image is loaded before scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCROLL_PAUSE_TIME = 1\n",
    "SCROLL_HEIGHT = 'document.body.scrollHeight'\n",
    "\n",
    "for i in range(50):\n",
    "    try:\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        browser.execute_script(\"window.scrollTo(0, {});\".format(SCROLL_HEIGHT))\n",
    "    except:\n",
    "        print(i)\n",
    "    finally:\n",
    "        print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCROLL_PAUSE_TIME = 6\n",
    "# SCROLL_HEIGHT = 400 #'document.body.scrollHeight'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "print('loading image: ')\n",
    "for i, tag in enumerate(browser.find_elements_by_xpath('//*[@id=\"products\"]/ul/li/a/div/img')):\n",
    "    # Scroll every 4 items\n",
    "#     if i % 4 == 0:\n",
    "#         browser.execute_script(\"window.scrollTo(0, {});\".format(SCROLL_HEIGHT))\n",
    "#         time.sleep(SCROLL_PAUSE_TIME)\n",
    "#         # limit to 40 images\n",
    "#         if i > 40:\n",
    "#             break\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        id_ = tag.get_attribute('id')\n",
    "        alt = tag.get_attribute('alt')\n",
    "        src = tag.get_attribute('src')\n",
    "        df.loc[i, 'id'] = id_.split('-')[2]\n",
    "        df.loc[i, 'ts'] = src.split('=')[1]\n",
    "        df.loc[i, 'description'] = alt\n",
    "        df.loc[i, 'source'] = src\n",
    "    except Exception as e:\n",
    "        print('\\n', repr(e))\n",
    "    print('{}{}'.format('\\b' * len(str(i)), i), end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headless scraping of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=os.path.abspath(driver_dir), chrome_options=chrome_options) \n",
    "driver.get(url)\n",
    "driver.current_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scroll until last image is loaded before scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCROLL_PAUSE_TIME = 1\n",
    "SCROLL_HEIGHT = 'document.body.scrollHeight'\n",
    "\n",
    "for i in range(50):\n",
    "    try:\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(SCROLL_HEIGHT))\n",
    "    except:\n",
    "        print(i)\n",
    "    finally:\n",
    "        print('ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in soup.find_all('img'):\n",
    "    print(image['src'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape images by tag name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for tag in driver.find_elements_by_tag_name('img'):\n",
    "    src = tag.get_attribute('src')\n",
    "    alt = tag.get_attribute('alt')\n",
    "#     print(alt, src)\n",
    "    images.append((alt, src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame()\n",
    "for i, tag in enumerate(driver.find_elements_by_tag_name('img')):\n",
    "#     time.sleep(0.5)\n",
    "    df_1.loc[i, 'src'] = tag.get_attribute('src')\n",
    "    df_1.loc[i,'alt'] = tag.get_attribute('alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape images by Xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath = '//*[@id=\"products\"]/ul/li/a/div/img'\n",
    "\n",
    "df_2 = pd.DataFrame()\n",
    "for i, tag in enumerate(driver.find_elements_by_xpath(xpath)):\n",
    "    try:\n",
    "        id_ = tag.get_attribute('id')\n",
    "        alt = tag.get_attribute('alt')\n",
    "        src = tag.get_attribute('src')\n",
    "        df_2.loc[i, 'id'] = id_.split('-')[2]\n",
    "        df_2.loc[i, 'ts'] = src.split('=')[1]\n",
    "        df_2.loc[i, 'description'] = alt\n",
    "        df_2.loc[i, 'source'] = src\n",
    "    except Exception as e:\n",
    "        print('\\n', repr(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index startrow/startcol N means value is inserted at N+1\n",
    "writer = pd.ExcelWriter('../_data/zara_mens_trousers.xlsx')\n",
    "df_1.to_excel(writer, 'trousers')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = None\n",
    "for key in images:\n",
    "    r = requests.get(styles[key], allow_redirects=True)\n",
    "    open('../_data/images/{}.jpg'.format(key), 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Take screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get_screenshot_as_file('sample_screenshot_2.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO click menu link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in soup.find_all('li'):\n",
    "    try:\n",
    "        image = tag.a.img\n",
    "        if tag.a.text[:3] == 'MAN':\n",
    "            print(tag.a.text)\n",
    "            tag.a.click()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menu_man = driver.find_element_by_partial_link_text('MAN').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO use search field interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field = driver.find_element_by_class_name(\"search\")  \n",
    "search_field\n",
    "# search_field.clear()\n",
    "# search_field.send_keys(keyword)\n",
    "# search_field.send_keys(Keys.RETURN)  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
