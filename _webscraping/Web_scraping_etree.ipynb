{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping rules\n",
    "- You should check a site's terms and conditions before you scrape them. It's their data and they likely have some rules to govern it.\n",
    "- Be nice - A computer will send web requests much quicker than a user can. Make sure you space out your requests a bit so that you don't hammer the site's server.\n",
    "- Scrapers break - Sites change their layout all the time. If that happens, be prepared to rewrite your code.\n",
    "- Web pages are inconsistent - There's sometimes some manual clean up that has to happen even after you've gotten your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import necessary modules</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requests\n",
    "- requests executes HTTP requests, like GET\n",
    "- The requests object holds the results of the request. This is page content and other items like HTTP status codes and headers.\n",
    "- requests only gets the page content without any parsing.\n",
    "- Beautiful Soup does the parsing of the HTML and finding content within the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.zara.com/uk/en/search?searchTerm='\n",
    "keywords = input(\"Search: \")\n",
    "url += keywords\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get result page as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url, keywords=''):\n",
    "    response = requests.get(url + keywords)\n",
    "    if not response.status_code == 200:\n",
    "        return None\n",
    "    return BeautifulSoup(response.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_soup(url, keywords)\n",
    "soup.html;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headless Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()  \n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "chrome_options.binary_location = '/Applications/Google Chrome Canary.app/Contents/MacOS/Google Chrome Canary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=os.path.abspath('../_driver_headless/chromedriver'), chrome_options=chrome_options) \n",
    "driver.get(url)\n",
    "driver.current_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.HTML(driver.page_source)\n",
    "result = etree.tostring(tree, pretty_print=True, method=\"html\")\n",
    "result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[div for div in tree.xpath(\"//img\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Index starts @ 1 not 0\n",
    "[etree.tostring(node) for node in tree.xpath(\"/html/body/div[2]//a//img\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[etree.tostring(node)[:100] for node in tree.xpath(\"//div[2]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['class:{}, id:{}'.format(node.xpath(\"@class\"), node.xpath(\"@id\")) for node in tree.xpath(\"//div\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['class:{}, id:{}'.format(node.xpath(\"@class\"), node.xpath(\"@id\")) for node in tree.xpath(\"//section\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[etree.tostring(node) for node in tree.xpath(\"//*[@id='products']/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[etree.tostring(node) for node in tree.xpath(\"//ul[@class='product-list _productList']/*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[etree.tostring(node)[:100] for node in tree.xpath(\"//*[contains(., 'dress')]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['class:{}, id:{}'.format(node.xpath(\"@class\"), node.xpath(\"@name\")) for node in tree.xpath(\"//*[contains(., 'product')]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[etree.tostring(div)[:100] for div in tree.xpath(\"//section[@class='_results']\")] # product-list _productList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[etree.tostring(div)[:100] for div in tree.xpath(\"//section._results\")] # product-list _productList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[etree.tostring(div)[:100] for div in tree.xpath(\"//lu[@class='product-list _productList']\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[etree.tostring(div)[:100] for div in tree.xpath(\"//*[@class='product _product']\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.xpath(\"//*[@id='product-6504767']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.xpath(\"/html/body/div[2]/section\")\n",
    "product_list = [etree.tostring(li) for li in tree.xpath(\"/html/body/div[2]/section/div/section/ul/li\")]\n",
    "product_list\n",
    "# tree.xpath('//*[@id=\"product-6504767\"')\n",
    "tree.xpath('//div[@class=\"product-info _product-info\"]') # //a[@class=\"item _item\"]/@href')  # class=\"_ariaResults wai-aria-messages\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[li for li in product_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging in to a web server, e.g. wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store your credentials in a encrypted/protected file (line1 = name, line2 = pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../credentials.txt') as f:\n",
    "    contents = f.read().split('\\n')\n",
    "    username = contents[0]\n",
    "    password = contents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct object that contains requested login data\n",
    "Inspect the login-form in your browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>get the value of the login token</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_login_token(response):\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    token = soup.find('input', {'name': \"wpLoginToken\"}).get('value')\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    'wpName': username,\n",
    "    'wpPassword': password,\n",
    "    'wploginattempt': 'Log in',\n",
    "    'wpEditToken': '+\\\\',\n",
    "    'title': 'Special:UserLogin',\n",
    "    'authAction': 'login',\n",
    "    'force': '',\n",
    "    'wpForceHttps': '1',\n",
    "    'wpFromhttp': '1',\n",
    "    'wpLoginToken': 'get_login_token(response)'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Setup a session, login, and get data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with requests.session() as s:\n",
    "    response = s.get('https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Main+Page')\n",
    "    \n",
    "    # Set login token\n",
    "    payload['wpLoginToken'] = get_login_token(response)\n",
    "    \n",
    "    # Send the login request\n",
    "    response_post = s.post('https://en.wikipedia.org/w/index.php?title=Special:UserLogin&action=submitlogin&type=login',\n",
    "                           data=payload)\n",
    "    \n",
    "    # Get another page and check if we’re still logged in\n",
    "    response = s.get('https://en.wikipedia.org/wiki/Special:Watchlist')\n",
    "    data = BeautifulSoup(response.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.find('div', class_='mw-changeslist').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
