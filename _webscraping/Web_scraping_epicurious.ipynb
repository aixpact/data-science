{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping rules\n",
    "- You should check a site's terms and conditions before you scrape them. It's their data and they likely have some rules to govern it.\n",
    "- Be nice - A computer will send web requests much quicker than a user can. Make sure you space out your requests a bit so that you don't hammer the site's server.\n",
    "- Scrapers break - Sites change their layout all the time. If that happens, be prepared to rewrite your code.\n",
    "- Web pages are inconsistent - There's sometimes some manual clean up that has to happen even after you've gotten your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import necessary modules</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requests\n",
    "- requests executes HTTP requests, like GET\n",
    "- The requests object holds the results of the request. This is page content and other items like HTTP status codes and headers.\n",
    "- requests only gets the page content without any parsing.\n",
    "- Beautiful Soup does the parsing of the HTML and finding content within the HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requests - connect as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print('successfully connected, response code: {}'.format(response.status_code))\n",
    "    else:\n",
    "        print('connection failed')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.epicurious.com/search/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect(url);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requests pass search keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = input(\"Please enter the things you want to see in a recipe: \")\n",
    "connect(url + keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = 1000\n",
    "soup = BeautifulSoup(connect(url).content, 'lxml')\n",
    "print(soup.prettify()[:n_chars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get result page as function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_page(url, keywords=''):\n",
    "    response = requests.get(url + keywords)\n",
    "    if not response.status_code == 200:\n",
    "        return None\n",
    "    return BeautifulSoup(response.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = input(\"Please enter the things you want to see in a recipe: \")\n",
    "soup = result_page(url, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.body.div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>BS4 functions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find_all  \n",
    "list of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lines = 5\n",
    "all_a_tags = soup.find_all('a')\n",
    "print(type(all_a_tags))\n",
    "all_a_tags[:n_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find  \n",
    "first result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_tag = soup.find('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(div_tag), div_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a')[0] == soup.find('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursively apply on elements (traverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(soup\n",
    "    .find('div')\n",
    "    .find('a')\n",
    "    .get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find and find_all  \n",
    "as css selectors\n",
    "<li>using selector=value, e.g. class_='recipe-content-card')\n",
    "<li>using a dictionary, e.g. {'class':'recipe-content-card'}\n",
    "<li>class is a reserved word in python, please use as 'class' or class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = 'recipe-content-card'\n",
    "soup.find_all('article', class_=selector)[0] == results_page.find('article', {'class':selector})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_text() \n",
    "Returns the content enclosed in a tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('article', {'class':selector}).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get()\n",
    "Returns the value of a tag attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_tag = soup.find('article',{'class':selector})\n",
    "recipe_link = recipe_tag.find('a')\n",
    "link_url = recipe_link.get('href')\n",
    "recipe_content = recipe_tag.find('a').get_text()\n",
    "\n",
    "print('a tag: {}\\n - content: {}\\n - link url: {}\\n - link type: {} '.format(recipe_link, recipe_content, link_url, type(link_url)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipes(url, keywords='', selector=''):\n",
    "    recipe_list = []\n",
    "    try:\n",
    "        soup = result_page(url, keywords)\n",
    "        recipes = soup.find_all('article', class_=selector)\n",
    "        \n",
    "        for recipe in recipes:\n",
    "            recipe_link = url + recipe.find('a').get('href')\n",
    "            recipe_name = recipe.find('a').get_text()\n",
    "            try:\n",
    "                recipe_description = recipe.find('p', class_='dek').get_text()\n",
    "            except:\n",
    "                recipe_description = ''\n",
    "            recipe_list.append((recipe_name, recipe_link, recipe_description))\n",
    "            \n",
    "        return recipe_list\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.epicurious.com/search/'\n",
    "keywords = input('Please enter the things you want to see in a recipe: ')\n",
    "selector = 'recipe-content-card'\n",
    "get_recipes(url, keywords, selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipe ingredients and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe_info(url, keywords='', selector=''):\n",
    "    recipe_dict = {}\n",
    "    try:\n",
    "        soup = result_page(url, keywords)\n",
    "        ingredient_list, prep_steps_list = [], []\n",
    "        for ingredient in soup.find_all('li', class_='ingredient'):\n",
    "            ingredient_list.append(ingredient.get_text())\n",
    "            \n",
    "        for prep_step in soup.find_all('li', class_='preparation-step'):\n",
    "            prep_steps_list.append(prep_step.get_text().strip())\n",
    "            \n",
    "        recipe_dict['ingredients'], recipe_dict['preparation'] = ingredient_list, prep_steps_list\n",
    "        return recipe_dict\n",
    "    except:\n",
    "        return recipe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.epicurious.com'\n",
    "link = '/recipes/food/views/spicy-lemongrass-tofu-233844'\n",
    "recipe_info = get_recipe_info(url + link)\n",
    "recipe_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_recipes(url, keywords='', selector=''):\n",
    "    results = []\n",
    "    all_recipes = get_recipes(url, keywords, selector)\n",
    "    for recipe in all_recipes:\n",
    "        recipe_dict = get_recipe_info(recipe[1])\n",
    "        recipe_dict['name'] = recipe[0]\n",
    "        recipe_dict['description'] = recipe[2]\n",
    "        results.append(recipe_dict)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = input('Please enter the things you want to see in a recipe: ')\n",
    "selector = 'recipe-content-card'\n",
    "all_recipes = get_all_recipes(url, keywords, selector)\n",
    "all_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(all_recipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
