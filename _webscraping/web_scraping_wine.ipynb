{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping rules\n",
    "- You should check a site's terms and conditions before you scrape them. It's their data and they likely have some rules to govern it.\n",
    "- Be nice - A computer will send web requests much quicker than a user can. Make sure you space out your requests a bit so that you don't hammer the site's server.\n",
    "- Scrapers break - Sites change their layout all the time. If that happens, be prepared to rewrite your code.\n",
    "- Web pages are inconsistent - There's sometimes some manual clean up that has to happen even after you've gotten your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import necessary modules</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requests\n",
    "- requests executes HTTP requests, like GET\n",
    "- The requests object holds the results of the request. This is page content and other items like HTTP status codes and headers.\n",
    "- requests only gets the page content without any parsing.\n",
    "- Beautiful Soup does the parsing of the HTML and finding content within the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.jancisrobinson.com'\n",
    "red_ = '/learn/grape-varieties/red/'\n",
    "white_ = '/learn/grape-varieties/white/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print('successfully connected, response code: {}'.format(response.status_code))\n",
    "    else:\n",
    "        print('connection failed')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect(url+red_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Sgraping'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_page(url, keywords=''):\n",
    "    response = requests.get(url + keywords)\n",
    "    if not response.status_code == 200:\n",
    "        return None\n",
    "    return BeautifulSoup(response.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hrefs(url, tag, class_, keywords=''):\n",
    "    try:\n",
    "        results_page = result_page(url, keywords)\n",
    "        href_list = results_page.find_all(tag, class_=class_)[0].find_all('a')\n",
    "        return ['{}{}'.format(url, href.get('href')) for href in href_list]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_red = get_hrefs(url, 'ul', 'info-table', red_)\n",
    "hrefs_white = get_hrefs(url, 'ul', 'info-table', white_)\n",
    "hrefs_red[:5], hrefs_white[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grape_text(url, tag, class_1, class_2, tag_1, color, keywords=''):\n",
    "    try:\n",
    "        results_page = result_page(url, keywords)\n",
    "        grape = results_page.find_all(tag, class_=class_1)[0].find_all(tag_1)[0].get_text()\n",
    "        content = results_page.find_all(tag, class_=class_2)[0].get_text()\n",
    "        return grape, color ,content\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sgrape all varieties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grape_varieties(url, tag, class_1, class_2, tag_1, color):\n",
    "    grape_list = []\n",
    "    for color in colors:\n",
    "        hrefs = get_hrefs(url, 'ul', 'info-table', '/learn/grape-varieties/' + color)\n",
    "        for href in hrefs:\n",
    "            grape_list.append(get_grape_text(href, tag, class_1, class_2, tag_1, color))\n",
    "    return grape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url, tag, class_1, class_2, tag_1, colors = 'https://www.jancisrobinson.com', 'div', 'learn-header', 'row', 'h1', ['red', 'white']\n",
    "grape_list = get_grape_varieties(url, tag, class_1, class_2, tag_1, colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grapes = pd.DataFrame(grape_list)\n",
    "df_grapes.columns = ['Grape', 'Color', 'Description']\n",
    "df_grapes.info()\n",
    "df_grapes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean - remove excessive spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grapes['Grape'] = [str(x.strip()) for x in df_grapes['Grape']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to UTF (English alfabeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install unidecode\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode to english, removing special chars\n",
    "df_grapes['Grape_utf'] = [str(unidecode.unidecode(x).strip()) for x in df_grapes['Grape']]\n",
    "df_grapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the grapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_grapes\n",
    "df_grapes.to_csv('../_data/grape_descr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
