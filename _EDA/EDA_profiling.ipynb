{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA & Profiling\n",
    "\n",
    "This EDA is based on the <a href=\"https://www.kaggle.com/hugomathien/soccer\">European Soccer Database</a> with more than 25,000 matches and more than 10,000 players for European professional soccer seasons from 2008 to 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "customplot: contains functions written for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . | grep customplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%!\n",
    "mkdir customplot && touch ./customplot/__init__.py\n",
    "cp ../_pycode/customplot.py ./customplot/customplot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from customplot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data \n",
    "\n",
    "Download the data from: <a href=\"https://www.kaggle.com/hugomathien/soccer\">https://www.kaggle.com/hugomathien/soccer</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%find.. 'database.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your connection.\n",
    "cnx = sqlite3.connect('../_data/database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('select name from sqlite_master where type = \"table\";').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player = pd.read_sql_query(\"SELECT * FROM Player\", cnx)\n",
    "df_player.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr = pd.read_sql_query(\"SELECT * FROM Player_Attributes\", cnx)\n",
    "df_attr.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check nulls, NaN's, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr.isnull().any().any()\n",
    "'percentage null: '; df_attr.isnull().any().sum() / df_attr.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%precision 2\n",
    "df_attr.isnull().sum(axis=0).describe()\n",
    "df_attr.isnull().sum(axis=0).max() * 100 / df_attr.shape[0], 'max % NaN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr = df_attr.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr.isnull().sum(axis=0).max() * 100 / df_attr.shape[0], 'max % NaN'\n",
    "df_attr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr = df_attr.reindex(np.random.permutation(df_attr.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting: 'overall_rating' of a player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Correlation Analysis \n",
    "Next, we will check if 'penalties' is correlated to 'overall_rating'. We are using a similar selection operation, bu this time for all the rows and within the correlation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr[:10][['penalties', 'overall_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr['overall_rating'].corr(df_attr['penalties'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of potentially correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potentialFeatures = ['acceleration', 'curve', 'free_kick_accuracy', 'ball_control', 'shot_power', 'stamina']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check correlation coefficient of \"overall_rating\" of a player with each feature we added to the list as potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in potentialFeatures:\n",
    "    related = df_attr['overall_rating'].corr(df_attr[f])\n",
    "    print(\"%s: %f\" % (f, related))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr.columns.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['potential',  'crossing', 'finishing', 'heading_accuracy',\n",
    "       'short_passing', 'volleys', 'dribbling', 'curve', 'free_kick_accuracy',\n",
    "       'long_passing', 'ball_control', 'acceleration', 'sprint_speed',\n",
    "       'agility', 'reactions', 'balance', 'shot_power', 'jumping', 'stamina',\n",
    "       'strength', 'long_shots', 'aggression', 'interceptions', 'positioning',\n",
    "       'vision', 'penalties', 'marking', 'standing_tackle', 'sliding_tackle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_list = [(f, df_attr['overall_rating'].corr(df_attr[f])) for f in cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.DataFrame(corr_list, columns=['attributes', 'correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p25 = df_corr.describe().loc['25%',][0]\n",
    "p50 = df_corr.describe().loc['50%',][0]\n",
    "p75 = df_corr.describe().loc['75%',][0]\n",
    "p25, p50, p75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation of correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataframe(df, y_label):  \n",
    "    global p25, p50, p75\n",
    "    color = 'coral'\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 6)\n",
    "    plt.title(y_label)\n",
    "\n",
    "    ax = df['correlation'].plot(linewidth=3.3, color=color)\n",
    "    ax.axhline(p25, c='gray')\n",
    "    ax.axhline(p50, c='k')\n",
    "    ax.axhline(p75, c='gray')\n",
    "    ax.xaxis.grid()\n",
    "    ax.set_xticks(df.index)\n",
    "    ax.set_xticklabels(df.attributes, rotation=75); #Notice the ; (remove it and see what happens !)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataframe(df_corr, 'Player\\'s Overall Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation heatmap\n",
    "\n",
    "The features with highest correlation coefficients are indicative for high Overall Rating. However we are never sure if the top features are independent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.set(style=\"white\")\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "cor = df_attr.loc[:, cols].corr()\n",
    "cor.shape\n",
    "mask = np.zeros_like(cor)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "ax = sns.heatmap(cor, mask=mask, cmap=cmap, vmax=.85);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Players into similar groups\n",
    "\n",
    "We can group similar players based on certain features.\n",
    "\n",
    "<b>Note:</b> Generally, someone with domain knowledge needs to define important features. We could have also selected some of the features with highest correlation with overall_rating. However, it does not guarantee best outcome always as we are not sure if the top five features are independent. For example, if 4 of the 5 features depend on the remaining 1 feature, taking all 5 does not give new information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select features for clustering - looking for youg mid-field player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_features = ['reactions', 'short_passing', 'long_passing', 'vision', 'interceptions', 'standing_tackle', 'potential']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df_attr[sel_features].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform K-Means Clustering\n",
    "\n",
    "We use K-Means to cluster the selected features in K clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform scaling on the dataframe containing the features\n",
    "data = scale(df_select)\n",
    "\n",
    "# Define number of clusters\n",
    "k = 6\n",
    "\n",
    "# Train a model\n",
    "model = KMeans(init='k-means++', n_clusters=k, n_init=20).fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame with feature coords for each cluster center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_km = pd.DataFrame(model.cluster_centers_)\n",
    "df_km.columns = sel_features\n",
    "df_km['players'] = pd.value_counts(model.labels_, sort=False)\n",
    "df_km['cluster'] = df_km.index.astype(int)\n",
    "df_km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster profiles\n",
    "We have K clusters based on the selected features and visualise them as profiles for similar groups of players. Each point is the average value of the cluster for that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcast colors over data set\n",
    "repeat = len(data)//5 + len(data) % 5\n",
    "my_colors = list('brgykcm' * repeat)[:len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "plt.figure(figsize=(15,8)).gca().axes.set_ylim([-2.5, +2.5])\n",
    "df_km.pop('players')\n",
    "parallel_coordinates(df_km, 'cluster', color=my_colors, marker='o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict profile for all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_features = ['reactions', 'short_passing', 'long_passing', 'vision', 'interceptions', 'standing_tackle', 'potential']\n",
    "df_select = df_attr[sel_features].copy(deep=True)\n",
    "data = scale(df_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(data)\n",
    "df_attr['profile'] = pred\n",
    "df_attr.loc[:,['player_api_id', 'profile']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = df_attr['profile']==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Players and Players Attributes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_player.loc[:,['player_api_id', 'player_name', 'birthday', 'height', 'weight']], \n",
    "                    df_attr[profile], how='right', left_on='player_api_id', right_on='player_api_id')\n",
    "df_merge.sample(5)\n",
    "df_merge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['age'] = pd.to_datetime(df_merge['birthday']).dt.strftime('%Y')\n",
    "df_merge.pop('birthday')\n",
    "df_merge['date'] = pd.to_datetime(df_merge['date']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['age'] = 2018 - df_merge['age'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best mid field players fitting profile and ranked by age and overall rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = (df_merge['overall_rating']>65.) & (df_merge['potential']>70.) # & (df_merge['preferred_foot']=='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates = df_merge[M].groupby('player_api_id').min().sort_values(['age', 'potential', 'overall_rating'], ascending=[True, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['player_name', 'age', 'height', 'weight', 'preferred_foot', 'overall_rating'] + sel_features\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance in relation to overall-rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['height', 'weight', 'potential', 'crossing', 'finishing', 'heading_accuracy',\n",
    "        'short_passing', 'volleys', 'dribbling', 'curve', 'free_kick_accuracy',\n",
    "        'long_passing', 'ball_control', 'acceleration', 'sprint_speed',\n",
    "        'agility', 'reactions', 'balance', 'shot_power', 'jumping', 'stamina',\n",
    "        'strength', 'long_shots', 'aggression', 'interceptions', 'positioning',\n",
    "        'vision', 'penalties', 'marking', 'standing_tackle', 'sliding_tackle', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_candidates.pop('overall_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_candidates.loc[:, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data sets in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skills = pd.DataFrame(list(zip(X_train.columns.tolist(), lr.coef_)), columns=['skill', 'importance'])\n",
    "df_skills = df_skills.set_index('skill')\n",
    "df_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xkcd();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas plot\n",
    "df_skills.plot.barh(figsize=(16, 12))\n",
    "plt.title('Soccer skill weights (/1000)', size=24, loc='left', ha='center')\n",
    "\n",
    "# Plot axes handle (OOP)\n",
    "ax = plt.gca()\n",
    "\n",
    "# Spines\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Legend\n",
    "ax.legend([])\n",
    "\n",
    "# Axis labels\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "\n",
    "# Text\n",
    "for i, v in enumerate(df_skills['importance']):\n",
    "    ax.text(v+.002, i-.2, str(int(v *1000)), color='k', size=10)\n",
    "\n",
    "# Ticks & labels\n",
    "ax.yaxis.set_ticklabels(df_skills.index, size=14, ha='center')\n",
    "ax.xaxis.set_ticks([])\n",
    "ax.xaxis.set_ticklabels(df_skills['importance'], color='white');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model metrics: train & test prediction score\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_train)\n",
    "print(\"Train - Mean squared error: {:.2f}\".format(mean_squared_error(y_train, y_pred)))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Train - Variance score: {:.2f}'.format(r2_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "print(\"Test - Mean squared error: {:.2f}\".format(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Test - Variance score: {:.2f}'.format(r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
