{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"nyc_311_data_subset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>read_csv</b>: A pandas function that reads a comma separated file</h4>\n",
    "read_csv will try to format the data so that it is the correct type and will report any typing problems<br>\n",
    "It will also look for a header row. \n",
    "<br>http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(datafile)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Let's examine our data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Looks like Unique Key really is a unique key and can serve as an index</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(datafile,index_col='Unique Key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Columns 4 has mixed types</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Column 4 is incident zip</h4>\n",
    "Let's examine it<br>\n",
    "The unique() function returns unique values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Incident Zip'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Some issues</h4>\n",
    "<li>Sometimes zip is a float, other times it is a str\n",
    "<li>Zipcodes that are represented as floats and start with 0 are missing the first digit\n",
    "<li>Some zipcodes have the 4 digit extension added. Comparison becomes tough\n",
    "<li>What the heck is zip 0?\n",
    "<li>What about the missing (nan) values? The ? (question mark)? \"UNKNOWN\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The first step in data cleaning is to:</h2>\n",
    "<h3>Decide what to do with \"bad\" data (\"JFK\", \"UNKNOWN\", etc.). Convert to Nan or delete the record.</h3>\n",
    "<h3>Make sure all data in a column is in the correct format (convert floats to strings, get rid of the 4 digit extension)</h3>\n",
    "<h3>Decide what to do with missing values (NaNs)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>for \"Incident Zip\"</h3>\n",
    "<h4>we'll drop rows with NaN or bad data</h4>\n",
    "<h4>get rid of the 4 digit extension</h4>\n",
    "<h4>remove zips less than 10000 and greater than 19999</h4>\n",
    "<h3>Let's write a function that fixes zips</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_zip(input_zip):\n",
    "    try:\n",
    "        input_zip = int(float(input_zip))\n",
    "    except:\n",
    "        try:\n",
    "            input_zip = int(input_zip.split('-')[0])\n",
    "        except:\n",
    "            return np.NaN\n",
    "    if input_zip < 10000 or input_zip > 19999:\n",
    "        return np.NaN\n",
    "    return str(input_zip)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>And test it</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_zip('11211.00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Next, we'll apply this function to every element in input zip to get a revised column</h3>\n",
    "<h4>The pandas function \"apply\" applies a function to a dataframe column\n",
    "<li>fix_zip will be applied to each element of the Incident Zip column and we replace the existing column with the modified one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Incident Zip'] = data['Incident Zip'].apply(fix_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Incident Zip'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finally, we'll get rid of all rows that have zip == Nan</h3>\n",
    "<li>We don't have to, that's just a choice we're making</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Incident Zip'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Let's take a look at the columns again</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Closed Data, Latitude and Longitude all have missing values</h3>\n",
    "<h3>Let's get rid of them</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['Latitude'].notnull()) & (data['Longitude'].notnull())  & (data['Closed Date'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Let's take a look at Borough data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Borough'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Let's look at 'Unspecified'</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Borough']=='Unspecified'][['Agency','Incident Zip']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Looks like a lot of these are NYPD related</h4>\n",
    "<h4>Let's take a closer look</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Borough']=='Unspecified'].groupby('Agency').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Unspecified appears to have a systematic bias toward NYPD</h4>\n",
    "<h4>Though only a small proportion of NYPD complaints (see below)</h4>\n",
    "<h4>We have to decide whether to keep them or lose them!</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nypd_complaints_total = data[data['Agency']=='NYPD']['Borough'].count()\n",
    "nypd_unspecified = data[(data['Borough']=='Unspecified') & (data['Agency']==\"NYPD\")]['Borough'].count()\n",
    "percentage = nypd_unspecified/nypd_complaints_total*100\n",
    "print(\"%1.2f\"%percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>For now, we'll get rid of them. Unspecified will be hard to explain!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Borough'] != 'Unspecified']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dealing with time</h4>\n",
    "<li>Dates and times are best converted to datetime\n",
    "<li>That way they will be useful for analysis because we can compute timedelta objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "data['Created Date'] = data['Created Date'].apply(lambda x:datetime.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Created Date'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Closed Date'] = data['Closed Date'].apply(lambda x:datetime.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>We can create a new column that tracks the time it takes to close a complaint</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processing_time'] =  data['Closed Date'] - data['Created Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And look at summary statistics\n",
    "data['processing_time'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>There is some odd stuff here</h4>\n",
    "<li>Negative processing time?\n",
    "<li>Since our data is for two months, a max of 148 days worth checking out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Let's examine the negative processing time data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['processing_time']<datetime.timedelta(0,0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>And the large processing times as well</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['processing_time']>datetime.timedelta(148,0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Looks like the upper end makes sense but the negative times don't</h3>\n",
    "<h3>Though we need to explore this more, we'll get rid of negative times for now</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['processing_time']>=datetime.timedelta(0,0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Finally, let's write a function that incorporates all our changes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_311_data(datafile):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    #Add the fix_zip function\n",
    "    def fix_zip(input_zip):\n",
    "        try:\n",
    "            input_zip = int(float(input_zip))\n",
    "        except:\n",
    "            try:\n",
    "                input_zip = int(input_zip.split('-')[0])\n",
    "            except:\n",
    "                return np.NaN\n",
    "        if input_zip < 10000 or input_zip > 19999:\n",
    "            return np.NaN\n",
    "        return str(input_zip)\n",
    "    \n",
    "    #Read the file\n",
    "    df = pd.read_csv(datafile,index_col='Unique Key')\n",
    "    \n",
    "    #fix the zip\n",
    "    df['Incident Zip'] = df['Incident Zip'].apply(fix_zip)\n",
    "    \n",
    "    #drop all rows that have any nans in them (note the easier syntax!)\n",
    "    \n",
    "    df = df.dropna(how='any')\n",
    "    \n",
    "    #get rid of unspecified boroughs\n",
    "    df = df[df['Borough'] != 'Unspecified']\n",
    "    \n",
    "    #Convert times to datetime and create a processing time column\n",
    "    \n",
    "    import datetime\n",
    "    df['Created Date'] = df['Created Date'].apply(lambda x:datetime.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n",
    "    df['Closed Date'] = df['Closed Date'].apply(lambda x:datetime.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n",
    "    df['processing_time'] =  df['Closed Date'] - df['Created Date']\n",
    "    \n",
    "    #Finally, get rid of negative processing times and return the final data frame\n",
    "    \n",
    "    df = df[df['processing_time']>=datetime.timedelta(0,0,0)]\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_311_data('nyc_311_data_subset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
