{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with New York 311 dataset on Incident records by time and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas defaults\n",
    "# Show max 10 rows: head(5) ... tail(5)\n",
    "pd.set_option('max_rows', 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_csv\n",
    "- tries to format the data in correct type\n",
    "- looks for a header row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = '../data/nyc_311_data_subset-2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafile)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature exploration\n",
    "- for efficiency set priority in which you want to clean/engineer the data, e.g.:\n",
    "  - get rid of singletons\n",
    "  - get rid of unique identifiers\n",
    "  - get rid of irrelavant features\n",
    "  - order priority on non-null values:\n",
    "    - clean/engineer object types (multi types)\n",
    "    - clean/engineer date types\n",
    "    - clean/engineer float types\n",
    "    - clean/engineer integer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Unique Key'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 'Unique Key' is not so unique after all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Unique Key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incident zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Incident Zip'].unique();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types within Zipcodes:\n",
    "- 5 digit numbers\n",
    "- 5 digit numbers start with 0 \n",
    "- 4 digit numbers\n",
    "- 5 digits-4 digits number\n",
    "- 0\n",
    "- missing (nan), ?, 'UNKNOWN'\n",
    "- 'JFK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define valid version\n",
    "- 10000< valid NY zipcode <19999\n",
    "- NaN otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_zip(input_zip):\n",
    "    try:\n",
    "        # string numbers -> float numbers -> int numbers\n",
    "        # string words will raise exception\n",
    "        input_zip = int(float(input_zip))\n",
    "    except:\n",
    "        try:\n",
    "            # split '12345-1234' and take first part - remove last part\n",
    "            # string words will raise exception\n",
    "            input_zip = int(input_zip.split('-')[0])\n",
    "        except:\n",
    "            # string words -> NaN\n",
    "            return np.NaN\n",
    "        \n",
    "    # incorrect zipcodes -> NaN\n",
    "    if input_zip < 10000 or input_zip > 19999:\n",
    "        return np.NaN\n",
    "    return str(input_zip)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test suite\n",
    "- Fail fast!\n",
    "- Define border cases to break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = ['?', 0, '1234', '01234', '12345-1234', 'JFK', 'UNKNOWN', '12345']\n",
    "correct_cases = [np.NaN, np.NaN, np.NaN, np.NaN, '12345', np.NaN, np.NaN, '12345']\n",
    "\n",
    "for i, zip in enumerate(test_cases):\n",
    "    fixed = fix_zip(zip)\n",
    "    np.testing.assert_equal(fixed, correct_cases[i], err_msg='Zipcode {} is not cleaned correctly'.format(zip))\n",
    "    print('zip code: {}, fixed: {}'.format(zip, fixed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply function to feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Incident Zip'] = df['Incident Zip'].apply(fix_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Incident Zip'].unique();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check percentage of samples containing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_null(feature):\n",
    "    null_percentage = df[feature].isnull().sum() / df[feature].notnull().sum() * 100\n",
    "    print('Percentage of NaN in {}: {:.2f}%'.format(feature, null_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null('Incident Zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove samples from df containing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Incident Zip'].dropna(axis=0, inplace=True)\n",
    "df = df[df['Incident Zip'].notnull()]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check percentage of samples containing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null('Latitude'), perc_null('Longitude');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined percentage NaN's\n",
    "lat_lon_notnull = (df['Latitude'].notnull()) & (df['Longitude'].notnull())\n",
    "(len(df) - sum(lat_lon_notnull)) / len(df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove samples from df containing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[lat_lon_notnull]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null('Latitude'), perc_null('Longitude')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null('Closed Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Closed Date'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null('Closed Date')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Borough'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore 'Unspecified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Borough']=='Unspecified']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dive into relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Check Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency(df, feature, value, by='', n_top=5):\n",
    "    if by == '':\n",
    "        by = feature\n",
    "    return (df[df[feature]==value][by].value_counts()\n",
    "                                      .sort_values(ascending=False)\n",
    "                                      .nlargest(n_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency(df, 'Borough', 'Unspecified', 'Incident Zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency(df, 'Borough', 'Unspecified', 'Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency(df, 'Borough', 'Unspecified', 'Agency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency(df, 'Agency', 'NYPD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency(df, 'Borough', 'Unspecified', 'Agency') / frequency(df, 'Agency', 'NYPD')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove 'unspecified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Borough'] != 'Unspecified']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Borough'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert dates and time to datetime object\n",
    " - to compute and use analysis on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Created Date'] = df['Created Date'].apply(lambda x: datetime.datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Created Date'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Closed Date'] = df['Closed Date'].apply(lambda x:datetime.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create time elapsed feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processing_time'] =  df['Closed Date'] - df['Created Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And look at summary statistics\n",
    "df['processing_time'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore\n",
    " - negative processing time\n",
    " - our data is for two months, a max of 148 days worth checking out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Let's examine the negative processing time data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['processing_time'] < datetime.timedelta(0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>And the large processing times as well</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['processing_time'] > datetime.timedelta(148,0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Looks like the upper end makes sense but the negative times don't</h3>\n",
    "<h3>Though we need to explore this more, we'll get rid of negative times for now</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['processing_time'] >= datetime.timedelta(0,0,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Finally, let's write a function that incorporates all our changes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_311_data(datafile):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    #Add the fix_zip function\n",
    "    def fix_zip(input_zip):\n",
    "        try:\n",
    "            input_zip = int(float(input_zip))\n",
    "        except:\n",
    "            try:\n",
    "                input_zip = int(input_zip.split('-')[0])\n",
    "            except:\n",
    "                return np.NaN\n",
    "        if input_zip < 10000 or input_zip > 19999:\n",
    "            return np.NaN\n",
    "        return str(input_zip)\n",
    "    \n",
    "    #Read the file\n",
    "    df = pd.read_csv(datafile,index_col='Unique Key')\n",
    "    \n",
    "    #fix the zip\n",
    "    df['Incident Zip'] = df['Incident Zip'].apply(fix_zip)\n",
    "    \n",
    "    #drop all rows that have any nans in them (note the easier syntax!)\n",
    "    \n",
    "    df = df.dropna(how='any')\n",
    "    \n",
    "    #get rid of unspecified boroughs\n",
    "    df = df[df['Borough'] != 'Unspecified']\n",
    "    \n",
    "    #Convert times to datetime and create a processing time column\n",
    "    \n",
    "    import datetime\n",
    "    df['Created Date'] = df['Created Date'].apply(lambda x:datetime.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n",
    "    df['Closed Date'] = df['Closed Date'].apply(lambda x:datetime.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n",
    "    df['processing_time'] =  df['Closed Date'] - df['Created Date']\n",
    "    \n",
    "    #Finally, get rid of negative processing times and return the final data frame\n",
    "    \n",
    "    df = df[df['processing_time']>=datetime.timedelta(0,0,0)]\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_311_data('nyc_311_data_subset-2.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
