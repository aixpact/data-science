{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steepest descent to fit a Gaussian model\n",
    "\n",
    "The *Gradient descent* algorithm descends a pre-defined function.  \n",
    "\n",
    "Here we shall descend the $\\chi^2$ (chi squared) function which is both:  \n",
    " - a function of the parameters that we are to optimise\n",
    " - the data that the model is to fit to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from HeightsModule import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "If we have data for the heights of people in a population, it can be plotted as a histogram, i.e., a bar chart where each bar has a width representing a range of heights, and an area which is the probability of finding a person with a height in that range.\n",
    "We can look to model that data with a function, such as a Gaussian, which we can specify with two parameters, rather than holding all the data in the histogram.\n",
    "\n",
    "The Gaussian function is given as,\n",
    "$$f(\\mathbf{x};\\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{(\\mathbf{x} - \\mu)^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "The figure above shows the data in orange, the model in magenta, and where they overlap in green.\n",
    "This particular model has not been fit well - there is not a strong overlap.\n",
    "\n",
    "Recall from the videos the definition of $\\chi^2$ as the squared difference of the data and the model, i.e $\\chi^2 = |\\mathbf{y} - f(\\mathbf{x};\\mu, \\sigma)|^2$. This is represented in the figure as the sum of the squares of the pink and orange bars.\n",
    "\n",
    "Don't forget that $\\mathbf{x}$ an $\\mathbf{y}$ are represented as vectors here, as these are lists of all of the data points, the |*abs-squared*|${}^2$ encodes squaring and summing of the residuals on each bar.\n",
    "\n",
    "To improve the fit, we will want to alter the parameters $\\mu$ and $\\sigma$, and ask how that changes the $\\chi^2$.\n",
    "That is, we will need to calculate the Jacobian,\n",
    "$$ \\mathbf{J} = \\left[ \\frac{\\partial ( \\chi^2 ) }{\\partial \\mu} , \\frac{\\partial ( \\chi^2 ) }{\\partial \\sigma} \\right]\\;. $$\n",
    "\n",
    "Let's look at the first term, $\\frac{\\partial ( \\chi^2 ) }{\\partial \\mu}$, using the multi-variate chain rule, this can be written as,\n",
    "$$ \\frac{\\partial ( \\chi^2 ) }{\\partial \\mu} = -2 (\\mathbf{y} - f(\\mathbf{x};\\mu, \\sigma)) \\cdot \\frac{\\partial f}{\\partial \\mu}(\\mathbf{x};\\mu, \\sigma)$$\n",
    "With a similar expression for $\\frac{\\partial ( \\chi^2 ) }{\\partial \\sigma}$; try and work out this expression for yourself.\n",
    "\n",
    "The Jacobians rely on the derivatives $\\frac{\\partial f}{\\partial \\mu}$ and $\\frac{\\partial f}{\\partial \\sigma}$.\n",
    "Write functions below for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Gaussian function\n",
    "def f (x, mu, sig) :\n",
    "    return np.exp(-(x-mu)**2/(2*sig**2)) / np.sqrt(2*np.pi) / sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next up, the derivative of f with respect to μ\n",
    "def dfdmu (x, mu, sig) :\n",
    "    return f(x, mu, sig) * ((x-mu)/(sig**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally in this cell, the derivative of f with respect to σ\n",
    "def dfdsig (x, mu, sig) :\n",
    "    f = 1 / sig\n",
    "    g = 1 / np.sqrt(2*np.pi) * np.exp(-(x-mu)**2/(2*sig**2))\n",
    "    f1 = -1 / sig**2\n",
    "    g1 = g * ((x-mu)**2 / sig**2) * f\n",
    "    return f*g1 + f1*g  # f(x, mu, sig) * ((x-mu)**2/(sig**3)) * (-1/sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next recall that steepest descent shall move around in parameter space proportional to the negative of the Jacobian,\n",
    "i.e., $\\begin{bmatrix} \\delta\\mu \\\\ \\delta\\sigma \\end{bmatrix} \\propto -\\mathbf{J} $, with the constant of proportionality being the *aggression* of the algorithm.\n",
    "\n",
    "Modify the function below to include the $\\frac{\\partial ( \\chi^2 ) }{\\partial \\sigma}$ term of the Jacobian, the $\\frac{\\partial ( \\chi^2 ) }{\\partial \\mu}$ term has been included for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steepest descend algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_step (x, y, mu, sig, aggression):\n",
    "    \"\"\"aggression is step size?\"\"\"\n",
    "    J = np.array([\n",
    "        -2*(y - f(x, mu, sig)) @ dfdmu(x, mu, sig),\n",
    "        -2*(y - f(x, mu, sig)) @ dfdsig(x, mu, sig)])\n",
    "    step = -J * aggression\n",
    "    return step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the heights data, ranges and frequencies\n",
    "x, y = heights_data()\n",
    "\n",
    "# Next we'll assign trial values for these.\n",
    "mu, sig = 154, 7\n",
    "\n",
    "# We'll keep a track of these so we can plot their evolution.\n",
    "p = np.array([[mu, sig]])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 9))\n",
    "\n",
    "# Plot the histogram for our parameter guess\n",
    "histogram(f, [mu, sig], axes[0])\n",
    "\n",
    "# Do a few rounds of steepest descent.\n",
    "for i in range(50) :\n",
    "    dmu, dsig = steepest_step(x, y, mu, sig, 2000)\n",
    "    mu += dmu\n",
    "    sig += dsig\n",
    "    p = np.append(p, [[mu,sig]], axis=0)\n",
    "    \n",
    "# Plot the path through parameter space.\n",
    "contour(f, p, axes[1])\n",
    "\n",
    "# Plot the final histogram.\n",
    "histogram(f, [mu, sig], axes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the path taken through parameter space is not necesarily the most direct path, as with steepest descent we always move perpendicular to the contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
